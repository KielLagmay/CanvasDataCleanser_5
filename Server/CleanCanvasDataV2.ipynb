{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "from dateutil.parser import isoparse\n",
    "from DirectoryGenerator import DirectoryGenerator\n",
    "from DataReader import readJSONL\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirGen = DirectoryGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToStringId(idNum):\n",
    "    return 'id_' + str(idNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDateTime(date, time):\n",
    "    return datetime.strptime(date + \" \" + time, '%Y-%m-%d %H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDataFrame(canvasFile):\n",
    "    jsonDataItems = readJSONL(canvasFile)\n",
    "    df = pd.DataFrame.from_dict(jsonDataItems)\n",
    "    df['collected_at'] = convertToDateTime(canvasFile.split(dirGen.getDelimiter())[-2], canvasFile.split(dirGen.getDelimiter())[-1].split('.')[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTypeEventNameAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_role', 'metadata_event_name'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loggedInCountAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfLoggedIn = df.loc[df['metadata_event_name'] == \"logged_in\"]\n",
    "    dfAgg = dfLoggedIn.groupby(['metadata_event_time_date'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loggedInCountPerUserAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfLoggedIn = df.loc[df['metadata_event_name'] == \"logged_in\"]\n",
    "    dfAgg = dfLoggedIn.groupby(['metadata_event_time_date', 'metadata_user_id'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assetCategoryPerContextAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "        dfAssets = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "        dfAgg = dfAssets.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_type', 'body_category'])['collected_at'].count()\n",
    "        result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "        result = result.loc[result['metadata_context_type'] == 'Course']\n",
    "        result.drop(['metadata_context_type'], axis = 1, inplace = True)\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userRoleListPerDatetime(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    dfUserRoleList = df.groupby(['collected_at', 'metadata_user_id', 'metadata_context_role'])['collected_at'].count().to_frame(name = 'total').reset_index()\n",
    "    dfUserRoleList.drop(['total'], axis = 1, inplace = True)\n",
    "    dfUserRoleList['metadata_user_id'] = dfUserRoleList['metadata_user_id'].apply(convertToStringId)\n",
    "    return dfUserRoleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversationNetworkAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "        dfConversations = df.loc[df['metadata_event_name'] == 'conversation_message_created']\n",
    "    \n",
    "        dfFromTo = dfConversations.groupby(['metadata_event_time_date', 'metadata_user_id', 'body_author_id', 'body_conversation_id'])['collected_at'].count().to_frame(name = 'total').reset_index()\n",
    "        dfFromTo['body_author_id'] = dfFromTo['body_author_id'].apply(lambda nodeId: \"auth_\" + str(nodeId))\n",
    "        dfFromTo['body_conversation_id'] = dfFromTo['body_conversation_id'].apply(lambda nodeId: \"conv_\" + str(nodeId))\n",
    "        dfFromTo['metadata_user_id'] = dfFromTo['metadata_user_id'].apply(convertToStringId)\n",
    "        return dfFromTo\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseDiscussionUserEntriesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_created\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_discussion_topic_id\", \"body_user_id\"])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseDiscussionUserEntriesWithRepliesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_created\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_event_name', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_assignment_id\", \"body_discussion_topic_id\", \"body_discussion_entry_id\", \"body_submission_id\", \"body_user_id\", \"body_parent_discussion_entry_id\", \"body_text\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    df = df.fillna(value={\"body_parent_discussion_entry_id\": 0})\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    result[\"body_discussion_entry_id\"] = result[\"body_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    result[\"body_parent_discussion_entry_id\"] = result[\"body_parent_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseGradedDiscussionUserEntriesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_submitted\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_event_time', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_discussion_topic_id\", \"body_user_id\"])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseGradedDiscussionUserEntriesWithRepliesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_submitted\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_event_name', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_assignment_id\", \"body_discussion_topic_id\", \"body_discussion_entry_id\", \"body_submission_id\", \"body_user_id\", \"body_parent_discussion_entry_id\", \"body_text\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    df = df.fillna(value={\"body_parent_discussion_entry_id\": 0, \"body_assignment_id\": 0, \"body_submission_id\": 0})\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    result[\"body_discussion_entry_id\"] = result[\"body_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    result[\"body_parent_discussion_entry_id\"] = result[\"body_parent_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    result['body_assignment_id'] = result['body_assignment_id'].apply(lambda nodeId: \"assignment_\" + str(nodeId))\n",
    "    result['body_submission_id'] = result['body_submission_id'].apply(lambda nodeId: \"submission_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discussionTopicCreationInfo(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_topic_created\"]\n",
    "    df = df.loc[df['body_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df = df[['collected_at', 'metadata_event_time', 'body_context_id', 'body_discussion_topic_id', 'metadata_user_id', 'metadata_context_role', 'body_title', 'body_body']]\n",
    "    dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['body_context_id', 'body_discussion_topic_id'])\n",
    "    result = dfAgg.reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace = True)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(lambda idNum: int(idNum) + 165820000000000000)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseInfo(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df = df.loc[df['metadata_event_name'] == \"course_created\"]\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df = df[['collected_at', 'metadata_event_time', 'body_course_id', 'body_created_at', 'body_name', 'body_updated_at']]\n",
    "        dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['body_course_id'])\n",
    "        result = dfAgg.reset_index()\n",
    "        result.drop(['index'], axis = 1, inplace = True)\n",
    "        result['body_course_id'] = result['body_course_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame({'collected_at': [np.nan], 'metadata_event_time': [np.nan], 'body_course_id': [np.nan], 'body_created_at': [np.nan], 'body_name': [np.nan], 'body_updated_at': [np.nan]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseSubmissionGrades(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df = df.loc[df['metadata_event_name'] == \"grade_change\"]\n",
    "        df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "        df = df.loc[df['body_grading_complete'] == True]\n",
    "        df = df.loc[df['body_muted'] == False]\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df = df[['collected_at', 'metadata_event_time', 'metadata_context_id', 'body_assignment_id', \"body_submission_id\", \"body_score\", \"body_points_possible\", \"body_student_id\", \"body_user_id\"]]\n",
    "        dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['metadata_context_id', 'body_assignment_id', \"body_submission_id\", \"body_student_id\", \"body_user_id\"], keep=\"last\")\n",
    "        result = dfAgg.reset_index()\n",
    "        result.drop(['index'], axis = 1, inplace = True)\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "        result['body_assignment_id'] = result['body_assignment_id'].apply(lambda nodeId: \"assignment_\" + str(nodeId))\n",
    "        result['body_submission_id'] = result['body_submission_id'].apply(lambda nodeId: \"submission_\" + str(nodeId))\n",
    "        result['body_student_id'] = result['body_student_id'].apply(lambda nodeId: \"student_\" + str(nodeId))\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame({'collected_at': [np.nan], 'metadata_event_time': [np.nan], 'metadata_context_id': [np.nan], 'body_assignment_id': [np.nan], \"body_submission_id\": [np.nan], \"body_score\": [np.nan], \"body_points_possible\": [np.nan], \"body_student_id\": [np.nan], \"body_user_id\": [np.nan]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleCanvasDataCleanser(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    # Some dataframe manipulation algorithms here courtesy of Pandas\n",
    "    result = df\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
