{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "from dateutil.parser import isoparse\n",
    "from DirectoryGenerator import DirectoryGenerator\n",
    "from DataReader import readJSONL\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirGen = DirectoryGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToStringId(idNum):\n",
    "    return 'id_' + str(idNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDateTime(date, time):\n",
    "    return datetime.strptime(date + \" \" + time, '%Y-%m-%d %H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDataFrame(canvasFile):\n",
    "    jsonDataItems = readJSONL(canvasFile)\n",
    "    df = pd.DataFrame.from_dict(jsonDataItems)\n",
    "    df['collected_at'] = convertToDateTime(canvasFile.split(dirGen.getDelimiter())[-2], canvasFile.split(dirGen.getDelimiter())[-1].split('.')[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordCount(text):\n",
    "    return len(re.findall(r'\\w+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTypeCourseAllLogsAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_role', 'metadata_context_id'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTypeCourseUserAllLogsAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_role', 'metadata_user_id', 'metadata_context_id'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTypeEventNameAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_role', 'metadata_event_name'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTypeCourseEventNameAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_role', 'metadata_context_id', 'metadata_event_name'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTypeUserCourseEventNameAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_role', 'metadata_context_id', 'metadata_user_id', 'metadata_event_name'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseEventNameAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_event_name'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loggedInCountAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfLoggedIn = df.loc[df['metadata_event_name'] == \"logged_in\"]\n",
    "    dfAgg = dfLoggedIn.groupby(['metadata_event_time_date'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loggedInCountPerUserAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfLoggedIn = df.loc[df['metadata_event_name'] == \"logged_in\"]\n",
    "    dfAgg = dfLoggedIn.groupby(['metadata_event_time_date', 'metadata_user_id'])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assetCategoryPerContextAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "        dfAssets = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "        dfAgg = dfAssets.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_type', 'body_category'])['collected_at'].count()\n",
    "        result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "        result = result.loc[result['metadata_context_type'] == 'Course']\n",
    "        result.drop(['metadata_context_type'], axis = 1, inplace = True)\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assetsPerContextAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "        dfAssets = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "        dfAgg = dfAssets.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_type', 'body_category', 'body_asset_id'])['collected_at'].count().to_frame(name = 'total_logs').reset_index()\n",
    "        result = dfAgg.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_type', 'body_category'])['body_asset_id'].count().to_frame(name = 'total').reset_index()\n",
    "        result = result.loc[result['metadata_context_type'] == 'Course']\n",
    "        result.drop(['metadata_context_type'], axis = 1, inplace = True)\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assetCategoryPerContextPerUserAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "        dfAssets = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "        dfAssets = dfAssets.loc[dfAssets['metadata_context_type'] == 'Course']\n",
    "        result = dfAssets.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', 'body_category'])['collected_at'].count().to_frame(name = 'total').reset_index()\n",
    "        result.drop(['metadata_context_type'], axis = 1, inplace = True)\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assetAccessesPerContextPerStudentAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        dfAssets = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "        dfAssets = dfAssets.loc[dfAssets['metadata_context_type'] == 'Course']\n",
    "        dfAssets = dfAssets.loc[dfAssets['metadata_context_role'] == 'StudentEnrollment']\n",
    "        result = dfAssets[['metadata_event_time', 'metadata_context_id', 'metadata_user_id', 'body_asset_id', 'body_category']]\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "        result['body_asset_id'] = result['body_asset_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userRoleListPerDatetime(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    dfUserRoleList = df.groupby(['collected_at', 'metadata_user_id', 'metadata_context_role'])['collected_at'].count().to_frame(name = 'total').reset_index()\n",
    "    dfUserRoleList.drop(['total'], axis = 1, inplace = True)\n",
    "    dfUserRoleList['metadata_user_id'] = dfUserRoleList['metadata_user_id'].apply(convertToStringId)\n",
    "    return dfUserRoleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversationNetworkAnalysis(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "        dfConversations = df.loc[df['metadata_event_name'] == 'conversation_message_created']\n",
    "    \n",
    "        dfFromTo = dfConversations.groupby(['metadata_event_time_date', 'metadata_user_id', 'body_author_id', 'body_conversation_id'])['collected_at'].count().to_frame(name = 'total').reset_index()\n",
    "        dfFromTo['body_author_id'] = dfFromTo['body_author_id'].apply(lambda nodeId: \"auth_\" + str(nodeId))\n",
    "        dfFromTo['body_conversation_id'] = dfFromTo['body_conversation_id'].apply(lambda nodeId: \"conv_\" + str(nodeId))\n",
    "        dfFromTo['metadata_user_id'] = dfFromTo['metadata_user_id'].apply(convertToStringId)\n",
    "        return dfFromTo\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseDiscussionUserEntriesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_created\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_discussion_topic_id\", \"body_user_id\"])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseDiscussionUserEntriesWordCountAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_created\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    df = df[['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_discussion_topic_id\", \"body_user_id\", \"body_text\"]]\n",
    "    df['word_count'] = df['body_text'].apply(getWordCount)\n",
    "    df['character_count'] = df['body_text'].apply(len)\n",
    "    df = df.drop(['body_text'], axis = 1)\n",
    "    totalWordCount = df.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', 'body_discussion_topic_id', 'body_user_id'])['word_count'].sum().to_frame('total_word_count').reset_index()\n",
    "    totalCharacterCount = df.groupby(['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', 'body_discussion_topic_id', 'body_user_id'])['character_count'].sum().to_frame('total_character_count').reset_index()\n",
    "    result = totalWordCount.merge(totalCharacterCount, on=['metadata_event_time_date', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', 'body_discussion_topic_id', 'body_user_id'])\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseDiscussionUserEntriesWithRepliesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_created\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_event_name', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_assignment_id\", \"body_discussion_topic_id\", \"body_discussion_entry_id\", \"body_submission_id\", \"body_user_id\", \"body_parent_discussion_entry_id\", \"body_text\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    df = df.fillna(value={\"body_parent_discussion_entry_id\": 0})\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    result[\"body_discussion_entry_id\"] = result[\"body_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    result[\"body_parent_discussion_entry_id\"] = result[\"body_parent_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseGradedDiscussionUserEntriesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_submitted\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df['metadata_event_time_date'] = df['metadata_event_time'].apply(lambda dt: dt.date())\n",
    "    dfAgg = df.groupby(['metadata_event_time_date', 'metadata_event_time', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_discussion_topic_id\", \"body_user_id\"])['collected_at'].count()\n",
    "    result = dfAgg.to_frame(name = 'total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseGradedDiscussionUserEntriesWithRepliesAnalysis(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_entry_submitted\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_event_name', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_assignment_id\", \"body_discussion_topic_id\", \"body_discussion_entry_id\", \"body_submission_id\", \"body_user_id\", \"body_parent_discussion_entry_id\", \"body_text\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    df = df.fillna(value={\"body_parent_discussion_entry_id\": 0, \"body_assignment_id\": 0, \"body_submission_id\": 0})\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "    result[\"body_discussion_entry_id\"] = result[\"body_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    result[\"body_parent_discussion_entry_id\"] = result[\"body_parent_discussion_entry_id\"].apply(lambda nodeId: \"entry_\" + str(nodeId))\n",
    "    result['body_assignment_id'] = result['body_assignment_id'].apply(lambda nodeId: \"assignment_\" + str(nodeId))\n",
    "    result['body_submission_id'] = result['body_submission_id'].apply(lambda nodeId: \"submission_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discussionTopicCreationInfo(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"discussion_topic_created\"]\n",
    "    df = df.loc[df['body_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df = df[['collected_at', 'metadata_event_time', 'body_context_id', 'body_discussion_topic_id', 'metadata_user_id', 'metadata_context_role', 'body_title', 'body_body']]\n",
    "    dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['body_context_id', 'body_discussion_topic_id'])\n",
    "    result = dfAgg.reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace = True)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(lambda idNum: int(idNum) + 165820000000000000)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_discussion_topic_id'] = result['body_discussion_topic_id'].apply(lambda nodeId: \"topic_\" + str(nodeId))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseInfo(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df = df.loc[df['metadata_event_name'] == \"course_created\"]\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df = df[['collected_at', 'metadata_event_time', 'body_course_id', 'body_created_at', 'body_name', 'body_updated_at']]\n",
    "        dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['body_course_id'])\n",
    "        result = dfAgg.reset_index()\n",
    "        result.drop(['index'], axis = 1, inplace = True)\n",
    "        result['body_course_id'] = result['body_course_id'].apply(convertToStringId)\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame({'collected_at': [np.nan], 'metadata_event_time': [np.nan], 'body_course_id': [np.nan], 'body_created_at': [np.nan], 'body_name': [np.nan], 'body_updated_at': [np.nan]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseSubmissionGrades(canvasFile):\n",
    "    try:\n",
    "        df = convertToDataFrame(canvasFile)\n",
    "        df = df.loc[df['metadata_event_name'] == \"grade_change\"]\n",
    "        df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "        df = df.loc[df['body_grading_complete'] == True]\n",
    "        df = df.loc[df['body_muted'] == False]\n",
    "        df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "        df = df[['collected_at', 'metadata_event_time', 'metadata_context_id', 'body_assignment_id', \"body_submission_id\", \"body_score\", \"body_points_possible\", \"body_student_id\", \"body_user_id\"]]\n",
    "        dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['metadata_context_id', 'body_assignment_id', \"body_submission_id\", \"body_student_id\", \"body_user_id\"], keep=\"last\")\n",
    "        result = dfAgg.reset_index()\n",
    "        result.drop(['index'], axis = 1, inplace = True)\n",
    "        result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "        result['body_user_id'] = result['body_user_id'].apply(lambda nodeId: \"user_\" + str(nodeId))\n",
    "        result['body_assignment_id'] = result['body_assignment_id'].apply(lambda nodeId: \"assignment_\" + str(nodeId))\n",
    "        result['body_submission_id'] = result['body_submission_id'].apply(lambda nodeId: \"submission_\" + str(nodeId))\n",
    "        result['body_student_id'] = result['body_student_id'].apply(lambda nodeId: \"student_\" + str(nodeId))\n",
    "        return result\n",
    "    except(KeyError):\n",
    "        return pd.DataFrame({'collected_at': [np.nan], 'metadata_event_time': [np.nan], 'metadata_context_id': [np.nan], 'body_assignment_id': [np.nan], \"body_submission_id\": [np.nan], \"body_score\": [np.nan], \"body_points_possible\": [np.nan], \"body_student_id\": [np.nan], \"body_user_id\": [np.nan]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allStudentSubmissionCreated(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == 'submission_created']\n",
    "    df = df.loc[df['body_workflow_state'] == 'submitted']\n",
    "    result = df[['body_submission_id', 'body_assignment_id', 'metadata_context_id', 'body_user_id', 'body_submitted_at', 'metadata_event_time', 'body_attempt']]\n",
    "    result['body_assignment_id'] = result['body_assignment_id'].apply(convertToStringId)\n",
    "    result['body_user_id'] = result['body_user_id'].apply(convertToStringId)\n",
    "    result['body_submission_id'] = result['body_submission_id'].apply(convertToStringId)\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allStudentSubmissionCommentCreated(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == 'submission_comment_created']\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[df['metadata_context_role'] == 'StudentEnrollment']\n",
    "    result = df.groupby(['metadata_event_time', 'metadata_context_id', 'body_submission_id', 'metadata_user_id'])['collected_at'].count().to_frame('submission_comments_count').reset_index()\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_submission_id'] = result['body_submission_id'].apply(lambda x: \"id_\" + str(165820000000000000 + int(x)))\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAssignmentCreation(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == 'assignment_created']\n",
    "    df = df.loc[(df['metadata_context_type'] == 'Course') & (df['body_context_type'] == 'Course')]\n",
    "    df = df.loc[df['body_workflow_state'] == 'published']\n",
    "    df = df[['metadata_context_id', 'metadata_event_time', 'body_assignment_id', 'body_context_id', 'body_submission_types']]\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['metadata_context_id', 'body_assignment_id', \"body_context_id\"])\n",
    "    result = dfAgg.reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace = True)\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['body_assignment_id'] = result['body_assignment_id'].apply(convertToStringId)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAssignmentDueDates(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[(df['metadata_event_name'] == 'assignment_created') | (df['metadata_event_name'] == 'assignment_updated')]\n",
    "    df = df.loc[(df['metadata_context_type'] == 'Course') & (df['body_context_type'] == 'Course')]\n",
    "    df = df.loc[df['body_workflow_state'] == 'published']\n",
    "    df = df[['metadata_context_id', 'metadata_event_time', 'body_assignment_id', 'body_context_id', 'body_due_at', 'body_lock_at', 'body_submission_types']]\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    dfAgg = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['metadata_context_id', 'body_assignment_id', \"body_context_id\"], keep=\"last\")\n",
    "    result = dfAgg.reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace = True)\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['body_assignment_id'] = result['body_assignment_id'].apply(convertToStringId)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseDiscussionForumTopicAccesses(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[df['body_asset_type'] == \"discussion_topic\"]\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_asset_id\", \"body_role\", \"body_asset_name\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result[\"body_discussion_topic_id\"] = result[\"body_asset_id\"].apply(lambda x: 'topic_' + str(int(x) - 165820000000000000))\n",
    "    result[\"body_asset_id\"] = result[\"body_asset_id\"].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseAssignmentAccesses(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[(df['body_category'] == \"assignments\") | (df[\"body_category\"] == \"quizzes\")]\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_asset_id\", \"body_role\", \"body_asset_name\", \"body_category\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result[\"body_asset_id\"] = result[\"body_asset_id\"].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseLessonAccesses(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[df['body_category'].isin(['conferences', 'external_urls', 'files', 'modules', 'pages', 'wiki'])]\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_context_id', 'metadata_context_role', 'metadata_user_id', \"body_asset_id\", \"body_role\", \"body_asset_name\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result[\"body_asset_id\"] = result[\"body_asset_id\"].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quizSubmissions(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"quiz_submitted\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[df['metadata_context_role'] == 'StudentEnrollment']\n",
    "    result = df[['metadata_context_id', 'metadata_event_time', 'metadata_user_id', 'body_quiz_id', 'body_submission_id']]\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result['body_quiz_id'] = result['body_quiz_id'].apply(convertToStringId)\n",
    "    result['body_submission_id'] = result['body_submission_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quizAccesses(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[(df['body_category'] == 'quizzes') & (df['body_asset_type'] == 'quizzes:quiz')]\n",
    "    df = df.loc[df['body_role'] == 'StudentEnrollment']\n",
    "    \n",
    "    columns = ['collected_at', 'metadata_event_time', 'metadata_context_id', 'metadata_user_id', \"body_asset_id\"]\n",
    "    for column in columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df = df[columns]\n",
    "    \n",
    "    result = df\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result[\"body_asset_id\"] = result[\"body_asset_id\"].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courseStudents(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == \"asset_accessed\"]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df = df.loc[(df['body_role'] == 'StudentEnrollment') | (df['body_role'] == 'StudentViewEnrollment')]\n",
    "    result = df.groupby(['metadata_event_time', 'metadata_context_id', 'metadata_user_id'])['collected_at'].count().to_frame('total').reset_index()\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['metadata_user_id'] = result['metadata_user_id'].apply(convertToStringId)\n",
    "    result.drop(['total'], axis = 1, inplace = True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCourseModules(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == 'module_created']\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df = df[['metadata_event_time', 'metadata_context_id', 'body_module_id']]\n",
    "    result = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['metadata_context_id', 'body_module_id']).reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace = True)\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['body_module_id'] = result['body_module_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCourseModulesPosition(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'].isin(['module_created', 'module_updated'])]\n",
    "    df = df.loc[df['metadata_context_type'] == 'Course']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df = df[['metadata_event_time', 'metadata_context_id', 'body_module_id', 'body_position']]\n",
    "    result = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['metadata_context_id', 'body_module_id'], keep='last').reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace = True)\n",
    "    result['metadata_context_id'] = result['metadata_context_id'].apply(convertToStringId)\n",
    "    result['body_module_id'] = result['body_module_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCourseModuleItems(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'] == 'module_item_created']\n",
    "    df = df.loc[df['body_context_type'] == 'Course']\n",
    "    df = df.loc[df['body_workflow_state'] == 'active']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df = df[['metadata_event_time', 'body_context_id', 'body_module_id', 'body_module_item_id']]\n",
    "    result = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['body_context_id', 'body_module_id', 'body_module_item_id']).reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace=True)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(convertToStringId)\n",
    "    result['body_module_id'] = result['body_module_id'].apply(convertToStringId)\n",
    "    result['body_module_item_id'] = result['body_module_item_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCourseModuleItemsPosition(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    df = df.loc[df['metadata_event_name'].isin(['module_item_created', 'module_item_updated'])]\n",
    "    df = df.loc[df['body_context_type'] == 'Course']\n",
    "    df = df.loc[df['body_workflow_state'] == 'active']\n",
    "    df['metadata_event_time'] = df['metadata_event_time'].apply(isoparse)\n",
    "    df = df[['metadata_event_time', 'body_context_id', 'body_module_id', 'body_module_item_id', 'body_position']]\n",
    "    result = df.sort_values(by='metadata_event_time').drop_duplicates(subset=['body_context_id', 'body_module_id', 'body_module_item_id'], keep='last').reset_index()\n",
    "    result.drop(['index'], axis = 1, inplace=True)\n",
    "    result['body_context_id'] = result['body_context_id'].apply(convertToStringId)\n",
    "    result['body_module_id'] = result['body_module_id'].apply(convertToStringId)\n",
    "    result['body_module_item_id'] = result['body_module_item_id'].apply(convertToStringId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleCanvasDataCleanser(canvasFile):\n",
    "    df = convertToDataFrame(canvasFile)\n",
    "    # Some dataframe manipulation algorithms here courtesy of Pandas\n",
    "    result = df\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
